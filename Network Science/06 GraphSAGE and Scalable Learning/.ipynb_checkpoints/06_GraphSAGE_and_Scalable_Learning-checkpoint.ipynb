{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTHXDXtVzU6K"
   },
   "source": [
    "# Introduction to GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.5.0+cu121.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.5.0+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, GATv2Conv, GCNConv\n",
    "from torch_geometric.utils import degree, to_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Print PyTorch version for compatibility checking\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWQGvb1w-IJP"
   },
   "source": [
    "# Dataset Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset():\n",
    "    \"\"\"\n",
    "    Load the PubMed dataset and display comprehensive statistics.\n",
    "    \n",
    "    PubMed Dataset Details:\n",
    "    - 19,717 scientific publications about diabetes\n",
    "    - Node features: 500-dimensional TF-IDF weighted word vectors\n",
    "    - Task: Multi-class classification (3 categories)\n",
    "      1. Diabetes mellitus experimental\n",
    "      2. Diabetes mellitus type 1\n",
    "      3. Diabetes mellitus type 2\n",
    "    \n",
    "    Returns:\n",
    "        dataset: The complete Planetoid dataset\n",
    "        data: The graph data object\n",
    "    \"\"\"\n",
    "    # Download and load the PubMed dataset\n",
    "    dataset = Planetoid(root='.', name=\"Pubmed\")\n",
    "    data = dataset[0]\n",
    "    \n",
    "    # Dataset-level statistics\n",
    "    print('=' * 60)\n",
    "    print(f'Dataset: {dataset}')\n",
    "    print('=' * 60)\n",
    "    print(f'Number of graphs: {len(dataset)}')\n",
    "    print(f'Number of nodes: {data.x.shape[0]:,}')\n",
    "    print(f'Number of features per node: {dataset.num_features}')\n",
    "    print(f'Number of classes: {dataset.num_classes}')\n",
    "    \n",
    "    # Graph structure statistics\n",
    "    print(f'\\nGraph Structure:')\n",
    "    print('-' * 60)\n",
    "    print(f'Training nodes: {sum(data.train_mask).item()} ({sum(data.train_mask).item()/data.x.shape[0]*100:.2f}%)')\n",
    "    print(f'Validation nodes: {sum(data.val_mask).item()} ({sum(data.val_mask).item()/data.x.shape[0]*100:.2f}%)')\n",
    "    print(f'Test nodes: {sum(data.test_mask).item()} ({sum(data.test_mask).item()/data.x.shape[0]*100:.2f}%)')\n",
    "    print(f'Edges are directed: {data.is_directed()}')\n",
    "    print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Graph has self-loops: {data.has_self_loops()}')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    return dataset, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset: Pubmed()\n",
      "============================================================\n",
      "Number of graphs: 1\n",
      "Number of nodes: 19,717\n",
      "Number of features per node: 500\n",
      "Number of classes: 3\n",
      "\n",
      "Graph Structure:\n",
      "------------------------------------------------------------\n",
      "Training nodes: 60 (0.30%)\n",
      "Validation nodes: 500 (2.54%)\n",
      "Test nodes: 1000 (5.07%)\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has self-loops: False\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset, data = load_and_explore_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rLIJs1t-Ki6"
   },
   "source": [
    "# Mini-batching with Neighbor Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbor_loader(data, num_neighbors=[5, 10], batch_size=16):\n",
    "    \"\"\"\n",
    "    Create a NeighborLoader for efficient mini-batch training with neighbor sampling.\n",
    "    \n",
    "    This is the key component that makes GraphSAGE scalable:\n",
    "    - Instead of using the entire graph, we sample a fixed number of neighbors\n",
    "    - num_neighbors=[5, 10] means:\n",
    "      * Sample 5 neighbors in the first layer (1-hop)\n",
    "      * Sample 10 neighbors for each of those in the second layer (2-hop)\n",
    "    - batch_size: Number of target nodes to process simultaneously\n",
    "    \n",
    "    Args:\n",
    "        data: Graph data object\n",
    "        num_neighbors: List specifying neighbors to sample at each layer\n",
    "        batch_size: Number of nodes to process in each batch\n",
    "    \n",
    "    Returns:\n",
    "        train_loader: DataLoader for training with neighbor sampling\n",
    "    \"\"\"\n",
    "    train_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,  # [5, 10] means 5 neighbors at layer 1, 10 at layer 2\n",
    "        batch_size=batch_size,         # Process 16 target nodes at once\n",
    "        input_nodes=data.train_mask,   # Only sample from training nodes\n",
    "        shuffle=True                   # Shuffle for better training\n",
    "    )\n",
    "    \n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subgraph Statistics from Neighbor Sampling:\n",
      "============================================================\n",
      "Subgraph 0: 392 nodes, 483 edges\n",
      "Subgraph 1: 295 nodes, 344 edges\n",
      "Subgraph 2: 257 nodes, 289 edges\n",
      "Subgraph 3: 165 nodes, 183 edges\n"
     ]
    }
   ],
   "source": [
    "# Create the neighbor loader\n",
    "train_loader = create_neighbor_loader(data)\n",
    "\n",
    "# Display information about generated subgraphs\n",
    "print(\"\\nSubgraph Statistics from Neighbor Sampling:\")\n",
    "print(\"=\" * 60)\n",
    "for i, subgraph in enumerate(train_loader):\n",
    "    print(f'Subgraph {i}: {subgraph.num_nodes} nodes, {subgraph.num_edges} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Utilities\n",
    "\n",
    "def plot_subgraphs(train_loader, num_subgraphs=4):\n",
    "    \"\"\"\n",
    "    Visualize the sampled subgraphs from the neighbor loader.\n",
    "    \n",
    "    Args:\n",
    "        train_loader: NeighborLoader object\n",
    "        num_subgraphs: Number of subgraphs to display\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    positions = [221, 222, 223, 224]\n",
    "    \n",
    "    for idx, (subdata, pos) in enumerate(zip(train_loader, positions[:num_subgraphs])):\n",
    "        # Convert PyG data to NetworkX for visualization\n",
    "        G = to_networkx(subdata, to_undirected=True)\n",
    "        \n",
    "        # Create subplot\n",
    "        ax = fig.add_subplot(pos)\n",
    "        ax.set_title(f'Subgraph {idx} ({subdata.num_nodes} nodes)', fontsize=20)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Draw the graph with node colors representing classes\n",
    "        nx.draw_networkx(\n",
    "            G,\n",
    "            pos=nx.spring_layout(G, seed=0),\n",
    "            with_labels=True,\n",
    "            node_color=subdata.y.numpy(),\n",
    "            cmap=\"cool\",\n",
    "            node_size=100,\n",
    "            font_size=6\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_degree_distribution(data, title=\"Node Degree Distribution\"):\n",
    "    \"\"\"\n",
    "    Plot the degree distribution of nodes in the graph.\n",
    "    \n",
    "    Understanding degree distribution helps in:\n",
    "    - Identifying hub nodes (high degree)\n",
    "    - Understanding graph connectivity\n",
    "    - Detecting potential issues (isolated nodes)\n",
    "    \n",
    "    Args:\n",
    "        data: Graph data object\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    # Calculate degree for each node\n",
    "    degrees = degree(data.edge_index[0]).numpy()\n",
    "    \n",
    "    # Count occurrences of each degree\n",
    "    degree_counts = Counter(degrees)\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.set_xlabel('Node Degree', fontsize=12)\n",
    "    ax.set_ylabel('Number of Nodes', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    \n",
    "    plt.bar(\n",
    "        degree_counts.keys(),\n",
    "        degree_counts.values(),\n",
    "        color='#0A047A',\n",
    "        edgecolor='black',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement GraphSage vs. GAT vs. GCN on Pubmed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE (Graph Sample and Aggregate) Model\n",
    "    \n",
    "    Key Features:\n",
    "    - Samples a fixed number of neighbors (makes it scalable)\n",
    "    - Aggregates neighbor features using mean pooling\n",
    "    - Can handle large graphs through mini-batching\n",
    "    \n",
    "    Architecture:\n",
    "    - Layer 1: SAGEConv (input_dim -> hidden_dim)\n",
    "    - ReLU activation\n",
    "    - Dropout (50%)\n",
    "    - Layer 2: SAGEConv (hidden_dim -> output_dim)\n",
    "    - Log softmax for classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        \"\"\"\n",
    "        Initialize GraphSAGE model.\n",
    "        \n",
    "        Args:\n",
    "            dim_in: Input feature dimension\n",
    "            dim_h: Hidden layer dimension\n",
    "            dim_out: Output dimension (number of classes)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # First SAGE convolution layer\n",
    "        self.sage1 = SAGEConv(dim_in, dim_h)\n",
    "        \n",
    "        # Second SAGE convolution layer\n",
    "        self.sage2 = SAGEConv(dim_h, dim_out)\n",
    "        \n",
    "        # Optimizer with weight decay for regularization\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=0.01,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Node features [num_nodes, num_features]\n",
    "            edge_index: Edge connectivity [2, num_edges]\n",
    "        \n",
    "        Returns:\n",
    "            h: Hidden representations\n",
    "            log_probs: Log probabilities for classification\n",
    "        \"\"\"\n",
    "        # First layer: SAGE convolution + ReLU\n",
    "        h = self.sage1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        \n",
    "        # Dropout for regularization (only during training)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        # Second layer: SAGE convolution\n",
    "        h = self.sage2(h, edge_index)\n",
    "        \n",
    "        # Return both hidden representation and log probabilities\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs, train_loader):\n",
    "        \"\"\"\n",
    "        Train the GraphSAGE model using mini-batch training.\n",
    "        \n",
    "        Args:\n",
    "            data: Full graph data (used for validation)\n",
    "            epochs: Number of training epochs\n",
    "            train_loader: NeighborLoader for mini-batch training\n",
    "        \"\"\"\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = self.optimizer\n",
    "        \n",
    "        self.train()\n",
    "        \n",
    "        for epoch in range(epochs + 1):\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            val_loss = 0\n",
    "            val_acc = 0\n",
    "            \n",
    "            # Mini-batch training loop\n",
    "            for batch in train_loader:\n",
    "                # Zero gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                _, out = self(batch.x, batch.edge_index)\n",
    "                \n",
    "                # Calculate loss on training nodes in this batch\n",
    "                loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Calculate training accuracy\n",
    "                pred = out[batch.train_mask].argmax(dim=1)\n",
    "                total_acc += accuracy(pred, batch.y[batch.train_mask])\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Validation metrics (on validation nodes in batch)\n",
    "                with torch.no_grad():\n",
    "                    val_loss += criterion(out[batch.val_mask], batch.y[batch.val_mask]).item()\n",
    "                    val_pred = out[batch.val_mask].argmax(dim=1)\n",
    "                    val_acc += accuracy(val_pred, batch.y[batch.val_mask])\n",
    "            \n",
    "            # Print metrics every 10 epochs\n",
    "            if epoch % 10 == 0:\n",
    "                avg_loss = total_loss / len(train_loader)\n",
    "                avg_acc = total_acc / len(train_loader) * 100\n",
    "                avg_val_loss = val_loss / len(train_loader)\n",
    "                avg_val_acc = val_acc / len(train_loader) * 100\n",
    "                \n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {avg_loss:.3f} | '\n",
    "                      f'Train Acc: {avg_acc:>6.2f}% | Val Loss: {avg_val_loss:.2f} | '\n",
    "                      f'Val Acc: {avg_val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Convolutional Network (GCN) Model\n",
    "    \n",
    "    Key Features:\n",
    "    - Uses spectral graph convolutions\n",
    "    - Processes the entire graph at once (not scalable to very large graphs)\n",
    "    - Smooth feature aggregation across neighbors\n",
    "    \n",
    "    Comparison with GraphSAGE:\n",
    "    - GCN: Processes full graph, slower but can be more accurate on small graphs\n",
    "    - GraphSAGE: Samples neighbors, faster and scalable\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        \"\"\"\n",
    "        Initialize GCN model.\n",
    "        \n",
    "        Args:\n",
    "            dim_in: Input feature dimension\n",
    "            dim_h: Hidden layer dimension\n",
    "            dim_out: Output dimension (number of classes)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "        \n",
    "        # Optimizer configuration\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=0.01,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward pass through GCN.\"\"\"\n",
    "        # Dropout on input features\n",
    "        h = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        # First GCN layer + ReLU\n",
    "        h = self.gcn1(h, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        \n",
    "        # Dropout\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        # Second GCN layer\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        \n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        \"\"\"\n",
    "        Train the GCN model on the full graph.\n",
    "        \n",
    "        Note: Unlike GraphSAGE, GCN processes the entire graph in each iteration.\n",
    "        \"\"\"\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = self.optimizer\n",
    "        \n",
    "        self.train()\n",
    "        \n",
    "        for epoch in range(epochs + 1):\n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            \n",
    "            # Calculate loss and accuracy on training set\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Validation metrics\n",
    "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "            val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "            \n",
    "            # Print metrics every 10 epochs\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>6.2f}% | '\n",
    "                      f'Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention Network (GAT) Model\n",
    "    \n",
    "    Key Features:\n",
    "    - Uses attention mechanism to weigh neighbor importance\n",
    "    - Multiple attention heads for learning diverse patterns\n",
    "    - Can focus on most relevant neighbors\n",
    "    \n",
    "    Comparison:\n",
    "    - Most expressive but slowest to train\n",
    "    - Best for graphs where neighbor importance varies significantly\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
    "        \"\"\"\n",
    "        Initialize GAT model.\n",
    "        \n",
    "        Args:\n",
    "            dim_in: Input feature dimension\n",
    "            dim_h: Hidden layer dimension per head\n",
    "            dim_out: Output dimension (number of classes)\n",
    "            heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # GAT layers with multiple attention heads\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
    "        self.gat2 = GATv2Conv(dim_h * heads, dim_out, heads=heads)\n",
    "        \n",
    "        # Optimizer with lower learning rate (GAT can be sensitive)\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=0.005,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward pass through GAT.\"\"\"\n",
    "        # Dropout on input\n",
    "        h = F.dropout(x, p=0.6, training=self.training)\n",
    "        \n",
    "        # First GAT layer + ELU activation\n",
    "        h = self.gat1(x, edge_index)\n",
    "        h = F.elu(h)\n",
    "        \n",
    "        # Dropout\n",
    "        h = F.dropout(h, p=0.6, training=self.training)\n",
    "        \n",
    "        # Second GAT layer\n",
    "        h = self.gat2(h, edge_index)\n",
    "        \n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        \"\"\"Train the GAT model.\"\"\"\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = self.optimizer\n",
    "        \n",
    "        self.train()\n",
    "        \n",
    "        for epoch in range(epochs + 1):\n",
    "            # Training\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Validation\n",
    "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "            val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "            \n",
    "            # Print metrics\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>6.2f}% | '\n",
    "                      f'Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"\n",
    "    Calculate classification accuracy.\n",
    "    \n",
    "    Args:\n",
    "        pred_y: Predicted labels\n",
    "        y: True labels\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Fraction of correct predictions\n",
    "    \"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "\n",
    "def test(model, data):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data: Graph data with test_mask\n",
    "    \n",
    "    Returns:\n",
    "        test_accuracy: Accuracy on test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)[data.test_mask]\n",
    "        acc = accuracy(pred, data.y[data.test_mask])\n",
    "    return acc\n",
    "\n",
    "\n",
    "def compare_models(graphsage_acc, gcn_acc, gat_acc):\n",
    "    \"\"\"\n",
    "    Visualize comparison of model accuracies.\n",
    "    \n",
    "    Args:\n",
    "        graphsage_acc: GraphSAGE test accuracy\n",
    "        gcn_acc: GCN test accuracy\n",
    "        gat_acc: GAT test accuracy\n",
    "    \"\"\"\n",
    "    models = ['GraphSAGE', 'GCN', 'GAT']\n",
    "    accuracies = [graphsage_acc, gcn_acc, gat_acc]\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#95E1D3']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(models, accuracies, color=colors, edgecolor='black', alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.2f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
    "    plt.title('Model Comparison on PubMed Dataset', fontsize=14, fontweight='bold')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "GraphSAGE(\n",
      "  (sage1): SAGEConv(500, 64, aggr=mean)\n",
      "  (sage2): SAGEConv(64, 3, aggr=mean)\n",
      ")\n",
      "\n",
      "Epoch   0 | Train Loss: 1.089 | Train Acc:  43.52% | Val Loss: 1.09 | Val Acc: 44.29%\n",
      "Epoch  10 | Train Loss: 0.056 | Train Acc: 100.00% | Val Loss: 0.40 | Val Acc: 91.67%\n",
      "Epoch  20 | Train Loss: 0.038 | Train Acc: 100.00% | Val Loss: 0.57 | Val Acc: 73.86%\n",
      "Epoch  30 | Train Loss: 0.027 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 80.42%\n",
      "Epoch  40 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: nan | Val Acc: nan%\n",
      "Epoch  50 | Train Loss: 0.019 | Train Acc: 100.00% | Val Loss: 0.47 | Val Acc: 84.97%\n",
      "Epoch  60 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.51 | Val Acc: 80.95%\n",
      "Epoch  70 | Train Loss: 0.015 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 72.11%\n",
      "Epoch  80 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 69.11%\n",
      "Epoch  90 | Train Loss: 0.015 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 76.16%\n",
      "Epoch 100 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 69.79%\n",
      "Epoch 110 | Train Loss: 0.015 | Train Acc: 100.00% | Val Loss: 0.49 | Val Acc: 85.71%\n",
      "Epoch 120 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.49 | Val Acc: 77.08%\n",
      "Epoch 130 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 0.46 | Val Acc: 90.62%\n",
      "Epoch 140 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 72.72%\n",
      "Epoch 150 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.45 | Val Acc: 86.79%\n",
      "Epoch 160 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.41 | Val Acc: 89.53%\n",
      "Epoch 170 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 0.72 | Val Acc: 66.01%\n",
      "Epoch 180 | Train Loss: 0.015 | Train Acc: 100.00% | Val Loss: 0.51 | Val Acc: 72.29%\n",
      "Epoch 190 | Train Loss: 0.018 | Train Acc: 100.00% | Val Loss: 0.78 | Val Acc: 71.67%\n",
      "Epoch 200 | Train Loss: 0.019 | Train Acc: 100.00% | Val Loss: 0.29 | Val Acc: 96.88%\n",
      "\n",
      "GraphSAGE Test Accuracy: 75.50%\n",
      "Training Time: 2.687614679336548 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train GraphSAGE\n",
    "start = time.time()\n",
    "graphsage = GraphSAGE(dataset.num_features, 64, dataset.num_classes)\n",
    "print(f\"\\nModel Architecture:\\n{graphsage}\\n\")\n",
    "graphsage.fit(data, epochs=200, train_loader=train_loader)\n",
    "graphsage_acc = test(graphsage, data) * 100\n",
    "print(f'\\nGraphSAGE Test Accuracy: {graphsage_acc:.2f}%')\n",
    "end = time.time()\n",
    "print(f\"Training Time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "GCN(\n",
      "  (gcn1): GCNConv(500, 64)\n",
      "  (gcn2): GCNConv(64, 3)\n",
      ")\n",
      "\n",
      "Epoch   0 | Train Loss: 1.099 | Train Acc:  26.67% | Val Loss: 1.10 | Val Acc: 28.00%\n",
      "Epoch  10 | Train Loss: 0.771 | Train Acc:  88.33% | Val Loss: 0.90 | Val Acc: 72.20%\n",
      "Epoch  20 | Train Loss: 0.392 | Train Acc:  95.00% | Val Loss: 0.69 | Val Acc: 74.80%\n",
      "Epoch  30 | Train Loss: 0.177 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 75.20%\n",
      "Epoch  40 | Train Loss: 0.142 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.20%\n",
      "Epoch  50 | Train Loss: 0.099 | Train Acc: 100.00% | Val Loss: 0.57 | Val Acc: 79.20%\n",
      "Epoch  60 | Train Loss: 0.096 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 76.40%\n",
      "Epoch  70 | Train Loss: 0.092 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 78.00%\n",
      "Epoch  80 | Train Loss: 0.099 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 77.80%\n",
      "Epoch  90 | Train Loss: 0.096 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 76.40%\n",
      "Epoch 100 | Train Loss: 0.059 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 76.20%\n",
      "Epoch 110 | Train Loss: 0.078 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 75.80%\n",
      "Epoch 120 | Train Loss: 0.066 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 77.00%\n",
      "Epoch 130 | Train Loss: 0.062 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 77.80%\n",
      "Epoch 140 | Train Loss: 0.057 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 76.60%\n",
      "Epoch 150 | Train Loss: 0.074 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 75.40%\n",
      "Epoch 160 | Train Loss: 0.060 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.80%\n",
      "Epoch 170 | Train Loss: 0.048 | Train Acc: 100.00% | Val Loss: 0.56 | Val Acc: 77.40%\n",
      "Epoch 180 | Train Loss: 0.042 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 76.20%\n",
      "Epoch 190 | Train Loss: 0.065 | Train Acc: 100.00% | Val Loss: 0.65 | Val Acc: 74.80%\n",
      "Epoch 200 | Train Loss: 0.066 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 74.40%\n",
      "\n",
      "GCN Test Accuracy: 79.70%\n",
      "Training Time: 13.546997308731079 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train GCN\n",
    "start = time.time()\n",
    "gcn = GCN(dataset.num_features, 64, dataset.num_classes)\n",
    "print(f\"\\nModel Architecture:\\n{gcn}\\n\")\n",
    "gcn.fit(data, epochs=200)\n",
    "gcn_acc = test(gcn, data) * 100\n",
    "print(f'\\nGCN Test Accuracy: {gcn_acc:.2f}%')\n",
    "end = time.time()\n",
    "print(f\"Training Time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "GAT(\n",
      "  (gat1): GATv2Conv(500, 64, heads=8)\n",
      "  (gat2): GATv2Conv(512, 3, heads=8)\n",
      ")\n",
      "\n",
      "Epoch   0 | Train Loss: 3.212 | Train Acc:   0.00% | Val Loss: 3.20 | Val Acc: 0.00%\n",
      "Epoch  10 | Train Loss: 0.707 | Train Acc:  93.33% | Val Loss: 0.87 | Val Acc: 72.20%\n",
      "Epoch  20 | Train Loss: 0.355 | Train Acc:  93.33% | Val Loss: 0.65 | Val Acc: 74.40%\n",
      "Epoch  30 | Train Loss: 0.181 | Train Acc:  95.00% | Val Loss: 0.58 | Val Acc: 77.20%\n",
      "Epoch  40 | Train Loss: 0.095 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 77.80%\n",
      "Epoch  50 | Train Loss: 0.086 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.00%\n",
      "Epoch  60 | Train Loss: 0.071 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 78.00%\n",
      "Epoch  70 | Train Loss: 0.071 | Train Acc: 100.00% | Val Loss: 0.57 | Val Acc: 76.80%\n",
      "Epoch  80 | Train Loss: 0.063 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.20%\n",
      "Epoch  90 | Train Loss: 0.061 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 75.60%\n",
      "Epoch 100 | Train Loss: 0.051 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 76.40%\n",
      "Epoch 110 | Train Loss: 0.046 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.00%\n",
      "Epoch 120 | Train Loss: 0.040 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 78.00%\n",
      "Epoch 130 | Train Loss: 0.041 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 75.80%\n",
      "Epoch 140 | Train Loss: 0.037 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 76.00%\n",
      "Epoch 150 | Train Loss: 0.033 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 75.60%\n",
      "Epoch 160 | Train Loss: 0.032 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 75.80%\n",
      "Epoch 170 | Train Loss: 0.032 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 74.80%\n",
      "Epoch 180 | Train Loss: 0.029 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 75.00%\n",
      "Epoch 190 | Train Loss: 0.026 | Train Acc: 100.00% | Val Loss: 0.65 | Val Acc: 75.80%\n",
      "Epoch 200 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 0.66 | Val Acc: 74.20%\n",
      "\n",
      "GAT Test Accuracy: 70.70%\n",
      "Training Time: 178.09288120269775 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train GAT\n",
    "start = time.time()\n",
    "gat = GAT(dataset.num_features, 64, dataset.num_classes)\n",
    "print(f\"\\nModel Architecture:\\n{gat}\\n\")\n",
    "gat.fit(data, epochs=200)\n",
    "gat_acc = test(gat, data) * 100\n",
    "print(f'\\nGAT Test Accuracy: {gat_acc:.2f}%')\n",
    "end = time.time()\n",
    "print(f\"Training Time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "GraphSAGE: 75.50%\n",
      "GCN:       79.70%\n",
      "GAT:       70.70%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GraphSAGE: {graphsage_acc:.2f}%\")\n",
    "print(f\"GCN:       {gcn_acc:.2f}%\")\n",
    "print(f\"GAT:       {gat_acc:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize comparison\n",
    "compare_models(graphsage_acc, gcn_acc, gat_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (GNN)",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
